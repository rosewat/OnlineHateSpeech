{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from preprocess import MyTokenizer\n",
    "from preprocess import get_vocab,get_corpus\n",
    "from preprocess import get_uncommon_words\n",
    "from preprocess import remove_uncommon_words_from_df\n",
    "from preprocess import preprocess_df\n",
    "\n",
    "from utilities import load_df\n",
    "from utilities import get_vocab_encoder\n",
    "from utilities import get_embedding_encoder\n",
    "\n",
    "from shape_data import prep_data\n",
    "from shape_data import random_embedding_array,embedding_array\n",
    "\n",
    "from train import Train\n",
    "from models import cnn_gru,cnn_gru_star,channel_model\n",
    "\n",
    "from utilities import word_has_vec\n",
    "import time\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import SpatialDropout1D, Dropout, Activation\n",
    "from keras.layers import MaxPooling1D,GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Conv1D, GRU, Bidirectional,LSTM\n",
    "from keras.layers import Flatten, concatenate\n",
    "#from keras.layers import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_COLS=['original','german','spanish']\n",
    "X_COLS=['original','german','french']\n",
    "#X_COLS=['comment_text']\n",
    "Y_COL=['label']\n",
    "#Y_COL=['identity_hate']\n",
    "VAL_SIZE=0.1 # if zero, no validation set \n",
    "Y_MAP = {'none': 0,'racism':1,'sexism':2}#or None for toxic embedding dataset\n",
    "EMBEDDINGS_FP='/Users/ellie/Downloads/embeddings/glove.840B.300d.txt'\n",
    "MAX_LEN=33\n",
    "MODELDIR='../models'\n",
    "BATCH_SIZE=1000\n",
    "EPOCHS=50\n",
    "DIM=300\n",
    "NUM_CLASSES=3 #2\n",
    "MON_SCORE='val_acc'\n",
    "MON_MODE='max'\n",
    "WEIGHTS_FILEP=''\n",
    "DATA_PATH='../cdata.csv'\n",
    "MODEL_FUNC=cnn_gru_star#alternatively 'cnn_gru_star' or 'channel_model'\n",
    "MODEL_NAME='mymodel'\n",
    "TRACKER_FN='tracker.csv'\n",
    "SAVE_MODEL_WEIGHTS=False\n",
    "LOAD_MODEL_WEIGHTS=False\n",
    "WEIGHTS_FILEP=''\n",
    "#TRAIN_TEST DATA STRUCTURE\n",
    "TRAIN_CHANNELS=False #change to true for the channel model\n",
    "TEST_CHANNELS=True \n",
    "VAL_SIZE=0.1\n",
    "CROSS_VAL=5\n",
    "\n",
    "#PREDICTION METHOD\n",
    "TRAIN_TEST_AUG=True \n",
    "NO_TEST_AUG=False #change to False if predicting on origial tweets only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=MyTokenizer(lower=True,remove_stopwords=False,remove_markers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If LOAD_MODEL_WEIGHTS==True:\n",
    "    with open(os.path.join(MODELDIR,WEIGHTS_FILEP), 'rb') as fp:\n",
    "        embeddings = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_df(DATA_PATH,x_cols=X_COLS,y_col=Y_COL,y_map=Y_MAP)\n",
    "ndf=preprocess_df(df,x_cols=X_COLS,tokenizer=tokenizer.preprocess_text)\n",
    "corp=get_corpus(ndf,x_cols=X_COLS)\n",
    "\n",
    "#uncomment the below lines to remove low frequency words\n",
    "#uncommon=get_uncommon_words(corp,thresh=4)\n",
    "#udf=remove_uncommon_words_from_df(ndf,x_cols=X_COLS,uncommon_list=uncommon)\n",
    "#corp=get_corpus(udf,x_cols=X_COLS)\n",
    "vocab=get_vocab(corp)\n",
    "encoder,decoder=get_vocab_encoder(vocab)\n",
    "\n",
    "\n",
    "vec_array=random_embedding_array(len(encoder),dim=DIM)\n",
    "#uncomment the below line if using pretrained embeddings\n",
    "#vec_array=embedding_array(encoder,embeddings)\n",
    "folds=prep_data(df=ndf,x_cols=X_COLS,y_col=Y_COL,encoder=encoder,cv=CROSS_VAL,\n",
    "                val_size=VAL_SIZE,max_len=MAX_LEN,train_channels=TRAIN_CHANNELS,test_channels=TEST_CHANNELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,fold in enumerate(folds): \n",
    "    fold_num=i+1\n",
    "\n",
    "    model_name=MODEL_NAME\n",
    "    if (fold_num) <=1:\n",
    "        path_datetime=time.strftime('%d-%H%M')\n",
    "        path=model_name+'_'+path_datetime+'fold-'+str(fold_num)\n",
    "    else:\n",
    "        path=model_name+'_'+path_datetime+'fold-'+str(fold_num)\n",
    "    \n",
    "    print('----------------')\n",
    "    print(path)\n",
    "    print('----------------')\n",
    "\n",
    "    model,summary=MODEL_FUNC(pad_len=MAX_LEN,vec_array=vec_array,num_classes=NUM_CLASSES)\n",
    "    train_model=Train(model,model_name,summary,x_cols=X_COLS,modeldir=MODELDIR)\n",
    "    \n",
    "    train_model.train(fold,model,path,\n",
    "                      total_epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      monitor_score=MON_SCORE,monitor_mode=MON_MODE,\n",
    "                      patience=5)\n",
    "    train_model.get_best_model()\n",
    "    #train_model.evaluate(fold,y_map=Y_MAP,tracker_fn='tracker.csv',predict_english_only=True)\n",
    "    \n",
    "    #to predict on all languages (by averaging probabilities)\n",
    "    train_model.evaluate(fold,y_map=Y_MAP,tracker_fn=TRACKER_FN,\n",
    "                         channel_probs=TRAIN_TEST_AUG,\n",
    "                         predict_english_only=NO_TEST_AUG,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_MODEL_WEIGHTS==True:\n",
    "    weights=model.get_weights()[0]\n",
    "    embeddings={}\n",
    "    for word,ix in encoder.items():\n",
    "        embeddings[word]=weights[ix]\n",
    "    with open(os.path.join(MODELDIR,WEIGHTS_FILEP), 'wb') as fp:\n",
    "        pkl.dump(embeddings,fp)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "thesis2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
